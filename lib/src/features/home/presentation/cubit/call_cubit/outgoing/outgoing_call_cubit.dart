import 'dart:async';
import 'dart:developer';
import 'package:audioplayers/audioplayers.dart';
import 'package:chitchat/src/core/constants/audio_assets.dart';
import 'package:chitchat/src/core/constants/strings.dart';
import 'package:chitchat/src/core/models/user_data.dart';
import 'package:chitchat/src/core/networking/models/call_history_model.dart';
import 'package:chitchat/src/core/networking/models/ice_candidate_model.dart';
import 'package:chitchat/src/core/networking/models/user_call_model.dart';
import 'package:chitchat/src/core/networking/models/user_model.dart';
import 'package:chitchat/src/core/networking/network_exceptions.dart';
import 'package:chitchat/src/core/routes/names.dart';
import 'package:chitchat/src/core/routes/router.dart';
import 'package:chitchat/src/features/home/data/repo/repo.dart';
import 'package:chitchat/src/features/home/presentation/cubit/call_cubit/webrtc.dart';
import 'package:equatable/equatable.dart';
import 'package:flutter/widgets.dart';
import 'package:flutter_bloc/flutter_bloc.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart';

part 'outgoing_call_state.dart';

class OutgoingCallCubit extends Cubit<OutgoingCallState> {
  OutgoingCallCubit({required this.homeRepository, required this.webrtc})
      : super(OutgoingCallState.initial());
  HomeRepository homeRepository;
  Webrtc webrtc;

  final player = AudioPlayer();
  StreamSubscription? outgoingDataSubscription;
  String callId = '';

  /// call status can be 7 values in firestore
  /// 0: call is initiated
  /// 1: call is answered
  /// 2: call is rejected
  /// 3: user in not answering
  /// 4: user in another call
  /// 5: call is deleted from singling server or caller ended call
  /// 6: call is finished

  void initiateCall({
    required UserModel userModelReceiver,
    required bool voiceCall,
  }) async {
    UserCallModel receiver =
        UserCallModel.convertUserModelToUserCallModel(userModelReceiver);
    if (voiceCall) {
      emit(state.copyWith(
          isAudioOn: true,
          isVideoOn: false,
          isFrontCameraSelected: false,
          isVideoOnUI: false));
    } else {
      emit(state.copyWith(
          isAudioOn: true,
          isVideoOn: true,
          isFrontCameraSelected: true,
          isVideoOnUI: true));
    }
    try {
      // update last seen for user
      await homeRepository.updateUserLastSeen(uId: UserData.currentUser!.uId);
      //we create a call document in firestore and use document id as call id
      String callId = await homeRepository.createCall(
          UserCallModel.convertUserModelToUserCallModel(UserData.currentUser!),
          receiver.uId,
          state.isVideoOn ? 'video' : 'audio');
      this.callId = callId;
      // we navigate to the call page
      Navigator.pushNamed(
        AppRouter.navigatorKey.currentContext!,
        RoutesName.outgoingCallPage,
        arguments: receiver,
      );

      await webrtc.initRenderers();

      await webrtc.setupPeerConnection(
        isAudioOn: state.isAudioOn,
        isVideoOn: state.isVideoOn,
        isFrontCameraSelected: state.isFrontCameraSelected,
        callId: callId,
      );

      // start playing sound
      await player.play(AssetSource(AudioAssets.outgoingCall));
      await player.setReleaseMode(ReleaseMode.loop);

      await createOutgoingCall(
        receiverData: receiver,
      );
    } catch (error) {
      log(error.toString());
      NetworkExceptions.showErrorDialog(error);
    }
  }

  createOutgoingCall({
    required UserCallModel receiverData,
  }) async {
    // List<RTCIceCandidate> iceCandidates = [];
    // once ICE candidate generated by the WebRTC connection
    // which contains information about potential network paths
    // to establish the peer-to-peer connection we store it in firestore
    webrtc.peerConnection?.onIceCandidate = (candidate) async {
      //  iceCandidates.add(candidate);
      await homeRepository.addIceCandidate(
          callId, IceCandidateModel.fromJson(candidate.toMap()));
    };
    // listen for the answer from the other peer
    outgoingDataSubscription =
        homeRepository.onCallDataChanged(callId).listen((data) async {
      if (data != null) {
        _mapCallStatusToAction(
          callStatus: data[FirebaseStrings.callStatus],
          answer: data[FirebaseStrings.answer],
          callId: callId,
          receiverData: receiverData,
        );
      }
    });
    log('creating offer');
    // create offer to initiate the call
    RTCSessionDescription offer = await webrtc.peerConnection!.createOffer();
    // using this offer to set the description of the session
    await webrtc.peerConnection!.setLocalDescription(offer);
    // store this offer in firestore
    homeRepository.sendOffer(callId, offer.toMap());
  }

  Future<void> _mapCallStatusToAction({
    required int callStatus,
    required String callId,
    required Map<String, dynamic>? answer,
    required UserCallModel receiverData,
  }) async {
    // when call status changes we stop the sound

    /// if call one of 3 states 2,3,4
    /// 2: call is rejected
    /// 3: user in not answering
    /// 4: user in another call
    /// 5: caller ended dead case here
    /// 6: user ended call after repose

    if (callStatus == 1) {
      player.stop();
      emit(state.copyWith(
        remoteRenderer: webrtc.remoteRenderer,
        localRenderer: webrtc.localRenderer,
      ));

      if (answer != null) {
        await webrtc.peerConnection!.setRemoteDescription(
          RTCSessionDescription(
            answer["sdp"],
            answer["type"],
          ),
        );
      }
      // mean user accepted the call start webRTC connection
      emit(state.copyWith(callStatus: callStatus));
    } else if (callStatus != 0) {
      player.stop();
      log('call ended with call status $callStatus');
      // remove call from singling collection
      await homeRepository.onCallEnd(
        callId,
      );
      // add data to call history for caller user
      await homeRepository.addCallToUserHistory(
        userID: UserData.currentUser!.uId,
        callData: CallHistoryModel(
            callType: state.isVideoOn ? 'video' : 'audio',
            userData: receiverData,
            callTime: DateTime.now().toString(),
            callStatus: callStatus,
            incoming: false),
      );
      emit(state.copyWith(callStatus: callStatus));
      exitOutgoingCallPage(showDelay: callStatus == 6 ? false : true);
    }
  }

  /// this function only used if user decide to close call
  /// before receiver response so its only way wit status code 5
  Future<void> exitCall({
    required UserCallModel otherUserData,
  }) async {
    try {
      player.stop();

      await homeRepository.onCallEnd(
        callId,
      );
      await homeRepository.addCallToUserHistory(
        userID: UserData.currentUser!.uId,
        callData: CallHistoryModel(
          callType: state.isVideoOn ? 'video' : 'audio',
          userData: otherUserData,
          callTime: DateTime.now().toString(),
          incoming: false,
          callStatus: 5,
        ),
      );
      exitOutgoingCallPage(showDelay: false);
    } catch (error) {
      NetworkExceptions.showErrorDialog(error);
    }
  }

  exitOutgoingCallPage({required bool showDelay}) async {
    outgoingDataSubscription?.cancel();
    outgoingDataSubscription = null;
    // player.dispose();
    if (showDelay) {
      await Future.delayed(Duration(seconds: 2));
    }
    Navigator.pop(AppRouter.navigatorKey.currentContext!);
    await homeRepository.updateUserLastSeen(uId: UserData.currentUser!.uId);

    emit(state.reset());
    webrtc.dispose();
  }

  mapCallStatusToMessage(int status) {
    switch (status) {
      case 0:
        return 'Calling...';
      case 1:
        return 'Connected';
      case 2:
        return 'User rejected call';
      case 3:
        return 'No response from user';
      case 4:
        return 'User in another call';
      // note not case 5 because 5 mean this call deleted from fire base
      case 6:
        return 'User Closed';
    }
  }

  toggleMic() {
    // change status
    emit(state.copyWith(isAudioOn: !state.isAudioOn));
    // enable or disable audio track
    webrtc.toggleMicRtc(state.isAudioOn);
  }

  toggleCamera() {
    // change status
    emit(state.copyWith(isVideoOn: !state.isVideoOn));
    // enable or disable video track
    webrtc.toggleCameraRtc(state.isAudioOn);
  }

  switchCamera() {
    emit(state.copyWith(isFrontCameraSelected: !state.isFrontCameraSelected));
    // change status
    webrtc.switchCameraRtc();
  }
}
